{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pickle\n",
    "import streamlit as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"./dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaner(Text):\n",
    "    Text=re.sub(r'[\\/`!@#$%^&*()_+{}<>,.?/\":;0-9]',' ',Text)\n",
    "    Text=Text.lower()\n",
    "    return Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df1.copy()\n",
    "data[\"cleaned_data\"]=\"\"\n",
    "data[\"cleaned_data\"]=data[\"Text\"].apply(lambda x:data_cleaner(x))\n",
    "data.drop(\"Text\",axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(data[\"cleaned_data\"])\n",
    "y=np.array(data[\"language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>cleaned_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Estonian</td>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swedish</td>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thai</td>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tamil</td>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21995</th>\n",
       "      <td>French</td>\n",
       "      <td>hors du terrain les années  et  sont des année...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21996</th>\n",
       "      <td>Thai</td>\n",
       "      <td>ใน พศ  หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21997</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>con motivo de la celebración del septuagésimoq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21998</th>\n",
       "      <td>Chinese</td>\n",
       "      <td>年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby i like》，由...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21999</th>\n",
       "      <td>Romanian</td>\n",
       "      <td>aprilie sonda spațială messenger a nasa și-a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       language                                       cleaned_data\n",
       "0      Estonian  klement gottwaldi surnukeha palsameeriti ning ...\n",
       "1       Swedish  sebes joseph pereira thomas  på eng the jesuit...\n",
       "2          Thai  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...\n",
       "3         Tamil  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...\n",
       "4         Dutch  de spons behoort tot het geslacht haliclona en...\n",
       "...         ...                                                ...\n",
       "21995    French  hors du terrain les années  et  sont des année...\n",
       "21996      Thai  ใน พศ  หลักจากที่เสด็จประพาสแหลมมลายู ชวา อินเ...\n",
       "21997   Spanish  con motivo de la celebración del septuagésimoq...\n",
       "21998   Chinese  年月，當時還只有歲的她在美國出道，以mai-k名義推出首張英文《baby i like》，由...\n",
       "21999  Romanian   aprilie sonda spațială messenger a nasa și-a ...\n",
       "\n",
       "[22000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2 ,random_state=29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MultinomialNB().fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(le,open(\"label_encoder\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_file = 'detector.model'\n",
    "pickle.dump(model, open(mod_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_file = 'vectorizer.pickle'\n",
    "pickle.dump(cv, open(vec_file, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_vectorizer = pickle.load(open('vectorizer.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickled_model = pickle.load(open('language_model.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(text):\n",
    "    x=cv.transform([text]).toarray()\n",
    "    lang=pickled_model.predict(x)\n",
    "    lang=cv.transform([lang]).toarray()\n",
    "    lang=le.inverse_transform(lang)\n",
    "    print(\"The langauge is\",lang[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hp\\Desktop\\Project Streamlit\\Exploring streamkit\\main.ipynb Cell 15\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/Project%20Streamlit/Exploring%20streamkit/main.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m prediction(\u001b[39m\"\u001b[39;49m\u001b[39mThe language detection service is used to identify the language of business texts, such as emails and chats. The service identifies the language of a text and the parts of that text where the language changes, down to the word level. Using the language detection service, Surveillance Insights can highlight and annotate the languages that are used in a text and help to identify potential suspicious activity.\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\hp\\Desktop\\Project Streamlit\\Exploring streamkit\\main.ipynb Cell 15\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/Project%20Streamlit/Exploring%20streamkit/main.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x\u001b[39m=\u001b[39mcv\u001b[39m.\u001b[39mtransform([text])\u001b[39m.\u001b[39mtoarray()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/Project%20Streamlit/Exploring%20streamkit/main.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m lang\u001b[39m=\u001b[39mpickled_model\u001b[39m.\u001b[39mpredict(x)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/Project%20Streamlit/Exploring%20streamkit/main.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m lang\u001b[39m=\u001b[39mcv\u001b[39m.\u001b[39;49mtransform([lang])\u001b[39m.\u001b[39mtoarray()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/Project%20Streamlit/Exploring%20streamkit/main.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m lang\u001b[39m=\u001b[39mle\u001b[39m.\u001b[39minverse_transform(lang)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hp/Desktop/Project%20Streamlit/Exploring%20streamkit/main.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe langauge is\u001b[39m\u001b[39m\"\u001b[39m,lang[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1432\u001b[0m, in \u001b[0;36mCountVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_vocabulary()\n\u001b[0;32m   1431\u001b[0m \u001b[39m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n\u001b[1;32m-> 1432\u001b[0m _, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, fixed_vocab\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   1433\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1434\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1274\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1272\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   1273\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1274\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1275\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1276\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         doc \u001b[39m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32mc:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mapply to a document.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m    preprocessed string\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[1;32m---> 69\u001b[0m     doc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m accent_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     doc \u001b[39m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "prediction(\"The language detection service is used to identify the language of business texts, such as emails and chats. The service identifies the language of a text and the parts of that text where the language changes, down to the word level. Using the language detection service, Surveillance Insights can highlight and annotate the languages that are used in a text and help to identify potential suspicious activity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Creating a function to be used in streamlit\n",
    "def main():\n",
    "    st.sidebar.header(\"Language Detector\")\n",
    "    st.sidebar.text(\"This is a web app that tell contain 20 language trained with a model,i.e the app can different 20 languages\")\n",
    "    st.sidebar.header(\"just fill in the information below\")\n",
    "    st.sidebar.text(\"Naive Bayes model was used\")\n",
    "pred_review_text=st.text_input(\"Enter a sentence in a particular language\")\n",
    "\n",
    "# A conditional statement to display the result using Streamlit\n",
    "if st.button(\"Detect\"):\n",
    "    text=pred_review_text\n",
    "    def prediction(text):\n",
    "        x=cv.transform([text]).toarray()\n",
    "        lang=pickled_model.predict(x)\n",
    "        lang=le.inverse_transform(lang)\n",
    "        st.write(lang[0])\n",
    "\n",
    "    # # x=cv.fit_transform([pred_review_text]).toarray()\n",
    "    # # lang=pickled_model.predict(pred_review_text)\n",
    "    # # lang=le.inverse_transform(lang)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
